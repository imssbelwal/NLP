#Stemming

import nltk
from nltk.stem.porter import *

p_stemmer = PorterStemmer()
words = ['run','runner','running','ran','runs','easily','fairly']
for word in words:
    print(word+' --> '+p_stemmer.stem(word))

#Snowball Stemmer
from nltk.stem.snowball import SnowballStemmer

s_stemmer = SnowballStemmer(language='english')
words = ['run','runner','running','ran','runs','easily','fairly']
for word in words:
    print(word+' --> '+s_stemmer.stem(word))

s_stemmer = SnowballStemmer(language='english')
words = ['consolingly']
for word in words:
    print(word+' --> '+s_stemmer.stem(word))

p_stemmer = PorterStemmer()
words = ['consolingly']
for word in words:
    print(word+' --> '+p_stemmer.stem(word))

s_stemmer = SnowballStemmer(language='english')
words = ['I am meetting him tomorrow at the meeting']
for word in words:
    print(word+' --> '+s_stemmer.stem(word))

p_stemmer = PorterStemmer()
words = ['I am meetting him tomorrow at the meeting']
for word in words:
    print(word+' --> '+p_stemmer.stem(word))

import spacy

!python -m spacy download en_core_web_sm

nlp = spacy.load('en_core_web_sm')

doc=nlp("I am meetting him tomorrow at the meeting")
for token in doc:
    print(token.text, token.pos_)

phrase = ('I am meetting him tomorrow at the meeting')
for word in phrase.split():
    print(word+ '-->' +p_stemmer.stem(word))

#lemmatization

doc1 = nlp(u"I am a runner running in a race because I love to run today")
for token in doc1:
    print(token.text, '\t', token.pos_, '\t',token.lemma, '\t', token.lemma_)

#Function to display lemmas
def show_lemmas (text) : 
    for token in text:
        print(f'{token.text:{12}}{token.pos_:{6}}{token.lemma:<{22}}{token.lemma_}')

doc2 = nlp(u"I saw eighteen mice today!")
show_lemmas(doc2)

doc3 = nlp(u'I am meetting him tomorrow at the meeting')
show_lemmas(doc3)

doc4 = nlp(u"That's an anormous automobile")
show_lemmas(doc4)

doc5 = nlp(u"WHO leads global efforts to expand universal health coverage. We direct and coordinate the world’s response to health emergencies. And we promote healthier lives – from pregnancy care through old age")
show_lemmas(doc5)

import spacy
nlp = spacy.load('en_core_web_sm')

from spacy.matcher import PhraseMatcher

matcher = PhraseMatcher(nlp.vocab)

with open('reaganomics.txt','r') as f:
    doc3 = nlp(f.read())

